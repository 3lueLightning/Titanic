{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add this notebook to a git repository https://www.youtube.com/watch?v=cnS813vKmPk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a class that stores parameters, this is done by subsetting a dictionary and adding the possibility to serialise the dictionary directly via pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameterdict(dict):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        \n",
    "    def store(self):\n",
    "        with open(self.file_name, 'ab') as dbfile:\n",
    "            pickle.dump(self, dbfile)                      \n",
    "        return\n",
    "    \n",
    "    def load(self):  \n",
    "        with open(self.file_name, 'rb') as dbfile:     \n",
    "            db = pickle.load(dbfile)  \n",
    "        return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default sagemaker IAM cannot access S3 buckets unless their name contains 'sagemaker' or 'SageMaker' or has any of those 2 words as tags. Therefore to avoid have setup another IAM with S3 permission we have simply added sagemaker to the S3 bucket's prefix name (which only represents the first part of the final name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "session = boto3.session.Session()\n",
    "\n",
    "PARAMETERS = parameterdict('titanic_parameters.pkl')\n",
    "PARAMETERS[\"my_region\"] = session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each S3 bucket name must be unique, not only in our own AWS account but in all of AWS therefore if the user specifies the bucket name directly there is a fair chance that that name will have already been take. Thsi will raise a BucketAlreadyExists error stating that 'The requested bucket name is not available'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4().hex[:20])])\n",
    "\n",
    "PARAMETERS[\"bucket_name\"] = create_bucket_name('s3.sagemaker.end2endtitanic.')\n",
    "bucket = s3.create_bucket(Bucket=PARAMETERS[\"bucket_name\"]\n",
    "                          , CreateBucketConfiguration={'LocationConstraint': PARAMETERS[\"my_region\"]})\n",
    "bucket = s3.Bucket( PARAMETERS[\"bucket_name\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETERS[\"bucket_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS[\"bucket_name\"] = 's3.sagemaker.end2endtitanic.7ededbe5308646a3adbc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = pathlib.Path('/home/ec2-user/SageMaker/Titanic/dataset')\n",
    "X = pd.read_csv(dataset_path/'train.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save original data (raw) into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored on s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/raw/train\n",
      "Data stored on s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/raw/test\n",
      "The dataset has a size of 8.9823e-05GB\n"
     ]
    }
   ],
   "source": [
    "data_partition = [['train', 'train.csv'], ['test', 'test.csv']]\n",
    "file_sizes = 0\n",
    "for i, (data_type, fn) in enumerate(data_partition):\n",
    "    key= f\"data/raw/{data_type}\"\n",
    "    data_path = f\"s3://{bucket.name}/{key}\"\n",
    "    if data_type == 'test':\n",
    "        PARAMETERS['raw_test_data_path'] = data_path\n",
    "    data_partition[i].append()\n",
    "    bucket.Object(key).upload_file(str(dataset_path/fn))\n",
    "    file_sizes += (dataset_path/fn).stat().st_size\n",
    "    print( f'Data stored on {data_partition[i][-1]}')\n",
    "\n",
    "file_sizes = file_sizes / 10**9 #converting size to GigaBytes\n",
    "PARAMETERS['data_set_size'] = file_sizes\n",
    "print(f\"The dataset has a size of {file_sizes}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survival rate 38.38%\n",
      "death odds 1.6\n"
     ]
    }
   ],
   "source": [
    "survival_rate = sum(X.Survived) / len(X)\n",
    "PARAMETERS['death_odds'] = (len(X) - sum(X.Survived)) / sum(X.Survived)\n",
    "print(f'survival rate {survival_rate:.2%}')\n",
    "print(f\"death odds {PARAMETERS['death_odds']:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(dataset_path/'test.csv')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age Cabin Embarked     Fare  \\\n",
       "0         0  22.0   NaN        S   7.2500   \n",
       "1         1  38.0   C85        C  71.2833   \n",
       "2         1  26.0   NaN        S   7.9250   \n",
       "3         1  35.0  C123        S  53.1000   \n",
       "4         0  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp            Ticket  \n",
       "0       3    male      1         A/5 21171  \n",
       "1       1  female      1          PC 17599  \n",
       "2       3  female      0  STON/O2. 3101282  \n",
       "3       1  female      1            113803  \n",
       "4       3    male      0            373450  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>363272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare                                          Name  \\\n",
       "0  34.5   NaN        Q   7.8292                              Kelly, Mr. James   \n",
       "1  47.0   NaN        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2  62.0   NaN        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "3  27.0   NaN        S   8.6625                              Wirz, Mr. Albert   \n",
       "4  22.0   NaN        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp   Ticket  \n",
       "0      0          892       3    male      0   330911  \n",
       "1      0          893       3  female      1   363272  \n",
       "2      0          894       2    male      0   240276  \n",
       "3      0          895       3    male      0   315154  \n",
       "4      1          896       3  female      1  3101298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format4xgboost(df):\n",
    "    header = set(df.columns.values.tolist())\n",
    "    if \"Survived\" in header:\n",
    "        sub_header = header - {'Survived'}\n",
    "        header = ['Survived'] + sorted(list(sub_header))    \n",
    "    else:\n",
    "        header = sorted(list(header))\n",
    "    df = df[header]\n",
    "    return df\n",
    "\n",
    "X = format4xgboost(X)\n",
    "display(X.head())\n",
    "X_test = format4xgboost(X_test)\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         int64\n",
       "Age            float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "Fare           float64\n",
       "Name            object\n",
       "Parch            int64\n",
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Sex             object\n",
       "SibSp            int64\n",
       "Ticket          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = pd.read_csv(\\'s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv\\'\\n                , names = [\\'Survived\\', \"Age\", \"Cabin\", \"Embarked\", \"Fare\", \"Name\"\\n                            , \"Parch\", \"PassengerId\", \"Pclass\", \"Sex\", \"SibSp\", \"Ticket\"])\\nX.head()\\nX_test = pd.read_csv(\\'s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv\\'\\n                , names = [ \"Age\", \"Cabin\", \"Embarked\", \"Fare\", \"Name\"\\n                            , \"Parch\", \"PassengerId\", \"Pclass\", \"Sex\", \"SibSp\", \"Ticket\"])\\nX_test.head()\\n'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X = pd.read_csv('s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv'\n",
    "                , names = ['Survived', \"Age\", \"Cabin\", \"Embarked\", \"Fare\", \"Name\"\n",
    "                            , \"Parch\", \"PassengerId\", \"Pclass\", \"Sex\", \"SibSp\", \"Ticket\"])\n",
    "X.head()\n",
    "X_test = pd.read_csv('s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv'\n",
    "                , names = [ \"Age\", \"Cabin\", \"Embarked\", \"Fare\", \"Name\"\n",
    "                            , \"Parch\", \"PassengerId\", \"Pclass\", \"Sex\", \"SibSp\", \"Ticket\"])\n",
    "X_test.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.Embarked values: ['S' 'C' 'Q' nan]; X_test.Embarked: ['Q' 'S' 'C']\n",
      "X.Sex values: ['S' 'C' 'Q' nan]; X_test.Sex: ['Q' 'S' 'C']\n"
     ]
    }
   ],
   "source": [
    "print(f'X.Embarked values: {X.Embarked.unique()}; X_test.Embarked: {X_test.Embarked.unique()}')\n",
    "print(f'X.Sex values: {X.Embarked.unique()}; X_test.Sex: {X_test.Embarked.unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing label encoding on the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "multi_encoder = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "def fit_transform_labels(df, names, only_transform=False):\n",
    "    categorical_cols = df.loc[:,names]\n",
    "    categorical_cols.fillna('nan', inplace=True) #LabelEncoder cannot handle NaNs\n",
    "    if only_transform:\n",
    "        fitted_cols = categorical_cols.apply(lambda col: multi_encoder[col.name].transform(col))\n",
    "    else:\n",
    "        fitted_cols = categorical_cols.apply(lambda col: multi_encoder[col.name].fit_transform(col))\n",
    "    return fitted_cols\n",
    "\n",
    "X[['Embarked', 'Sex']] = fit_transform_labels(X, ['Embarked', 'Sex'])\n",
    "X_test[['Embarked', 'Sex']] = fit_transform_labels(X_test, ['Embarked', 'Sex'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To then get back to the original data, simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked     Sex\n",
       "0        S    male\n",
       "1        C  female\n",
       "2        S  female\n",
       "3        S  female\n",
       "4        S    male"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['Embarked', 'Sex']].apply(lambda col: multi_encoder[col.name].inverse_transform(col)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  0.,  1., nan])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_back_nan(col):\n",
    "    try:\n",
    "        #find out what is the label of the NaN's\n",
    "        nan_label = multi_encoder[col.name].transform(['nan'])[0]\n",
    "    except ValueError:\n",
    "        return col\n",
    "    new_col = col.copy()\n",
    "    #replace that NaN label with np.nan\n",
    "    new_col[new_col == nan_label] = np.nan\n",
    "    return new_col\n",
    "\n",
    "X[['Embarked', 'Sex']] = X[['Embarked', 'Sex']].apply(convert_back_nan)\n",
    "X_test[['Embarked', 'Sex']] = X_test[['Embarked', 'Sex']].apply(convert_back_nan)\n",
    "fitted_cols.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['Survived', 'Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp']]\n",
    "X_test = X_test[['Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5d225e790db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_val = train_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1256e11595f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m \u001b[0;31m# python3; python2: BytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_partition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpartition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_partition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from io import StringIO # python3; python2: BytesIO \n",
    "\n",
    "data_partition = [['train', 'train.csv', X], ['validation', 'validation.csv', X_val], ['test', 'test.csv', X_test]]\n",
    "for partition in data_partition:\n",
    "    data_type, fn, df = partition\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, header=False, index=False)\n",
    "    key = f'data/for_xgboost/{fn}'\n",
    "    bucket.Object(key).put(Body=csv_buffer.getvalue())\n",
    "    partition[-1] = f's3://{PARAMETERS[\"bucket_name\"]}/{key}'\n",
    "    print(f'{data_type} saved to {partition[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train saved to s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/train.csv\n",
      "validation saved to s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/validation.csv\n",
      "test saved to s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv\n"
     ]
    }
   ],
   "source": [
    "data_partition = [['train', 'train.csv'], ['validation', 'validation.csv'], ['test', 'test.csv']]\n",
    "for partition in data_partition:\n",
    "    data_type, fn = partition\n",
    "    key = f'data/for_xgboost/{fn}'\n",
    "    partition.append(f's3://{PARAMETERS[\"bucket_name\"]}/{key}') \n",
    "    print(f'{data_type} saved to {partition[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS['data_partition'] = data_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the xgboost image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(PARAMETERS[\"my_region\"], 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the training, by setting the number of instances, instance type, EBS volume attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "s3_output_location = \"s3://{}/xgboost_model_sdk\".format(PARAMETERS['bucket_name'])\n",
    "xgb_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         #file sizes times 1.2 to have some margin but we need to allocate at least 1GB\n",
    "                                         train_volume_size = 1,#max( 1.2 * file_sizes, 1), \n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_class = 2,\n",
    "xgb_model.set_hyperparameters(max_depth = 5,\n",
    "                              eta = .2,\n",
    "                              gamma = 2,\n",
    "                              scale_pos_weight = 1.6, #PARAMETERS['death_odds'],\n",
    "                              silent = 0,\n",
    "                              objective = 'binary:logistic',\n",
    "                              num_round = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon Xgboost algorithm requires that data be provided to it via a list of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {}\n",
    "for partition in data_partition[:2]:\n",
    "    data_channels[partition[0]] = sagemaker.session.s3_input(partition[-1], content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15 18:56:15 Starting - Starting the training job...\n",
      "2019-07-15 18:56:16 Starting - Launching requested ML instances...\n",
      "2019-07-15 18:57:14 Starting - Preparing the instances for training.........\n",
      "2019-07-15 18:58:38 Downloading - Downloading input data\n",
      "2019-07-15 18:58:38 Training - Downloading the training image...\n",
      "2019-07-15 18:59:08 Uploading - Uploading generated training model\n",
      "2019-07-15 18:59:08 Completed - Training job completed\n",
      "\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-07-15:18:58:57:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-07-15:18:58:57:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 8464.18mb\u001b[0m\n",
      "\u001b[31m[2019-07-15:18:58:57:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[18:58:57] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[18:58:57] 668x7 matrix with 4676 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-07-15:18:58:57:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[18:58:57] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[18:58:57] 223x7 matrix with 1561 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[0]#011train-error:0.170659#011validation-error:0.242152\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[1]#011train-error:0.166168#011validation-error:0.251121\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[2]#011train-error:0.169162#011validation-error:0.237668\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[3]#011train-error:0.149701#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[4]#011train-error:0.137725#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[5]#011train-error:0.134731#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[6]#011train-error:0.134731#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[7]#011train-error:0.131737#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[8]#011train-error:0.131737#011validation-error:0.215247\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[9]#011train-error:0.131737#011validation-error:0.215247\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[10]#011train-error:0.124251#011validation-error:0.215247\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[11]#011train-error:0.122754#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[12]#011train-error:0.122754#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[13]#011train-error:0.124251#011validation-error:0.197309\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[14]#011train-error:0.125749#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[15]#011train-error:0.124251#011validation-error:0.201794\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[16]#011train-error:0.124251#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[17]#011train-error:0.122754#011validation-error:0.197309\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[18]#011train-error:0.116766#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 26 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[19]#011train-error:0.116766#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[20]#011train-error:0.115269#011validation-error:0.206278\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[21]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[22]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[23]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[24]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[25]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[26]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[27]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[28]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "\u001b[31m[18:58:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[29]#011train-error:0.115269#011validation-error:0.210762\u001b[0m\n",
      "Billable seconds: 51\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(inputs=data_channels,  logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAL END OF FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/xgboost_model_sdk/xgboost-2019-07-15-18-56-15-081/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(xgb_model.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model2 = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         #file sizes times 1.2 to have some margin but we need to allocate at least 1GB\n",
    "                                         train_volume_size = 1, #max( 1.2 * file_sizes, 1), \n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session(),\n",
    "                                         model_uri=xgb_model.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................!\n"
     ]
    }
   ],
   "source": [
    "batch_input = 's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv' # The location of the test dataset\n",
    "\n",
    "# The location to store the results of the batch transform job\n",
    "batch_output = f\"s3://{PARAMETERS['bucket_name']}/batch-inference\" \n",
    "\n",
    "transformer = xgb_model.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n",
    "\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS['latest_training_job_name'] = xgb_model.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_region': 'eu-west-1',\n",
       " 'bucket_name': 's3.sagemaker.end2endtitanic.7ededbe5308646a3adbc',\n",
       " 'latest_training_job_name': 'xgboost-2019-07-15-18-56-15-081',\n",
       " 'data_partition': [['train',\n",
       "   'train.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/train.csv'],\n",
       "  ['validation',\n",
       "   'validation.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/validation.csv'],\n",
       "  ['test',\n",
       "   'test.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv']]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_region': 'eu-west-1',\n",
       " 'bucket_name': 's3.sagemaker.end2endtitanic.7ededbe5308646a3adbc',\n",
       " 'latest_training_job_name': 'xgboost-2019-07-15-18-56-15-081',\n",
       " 'data_partition': [['train',\n",
       "   'train.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/train.csv'],\n",
       "  ['validation',\n",
       "   'validation.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/validation.csv'],\n",
       "  ['test',\n",
       "   'test.csv',\n",
       "   's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/for_xgboost/test.csv']],\n",
       " 'raw_test_data_path': 's3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/data/raw/test',\n",
       " 'data_set_size': 8.9823e-05,\n",
       " 'death_odds': 1.6}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           0\n",
       "5           1\n",
       "6           0\n",
       "7           1\n",
       "8           0\n",
       "9           1\n",
       "10          1\n",
       "11          1\n",
       "12          0\n",
       "13          1\n",
       "14          0\n",
       "15          0\n",
       "16          1\n",
       "17          1\n",
       "18          0\n",
       "19          1\n",
       "20          1\n",
       "21          0\n",
       "22          0\n",
       "23          1\n",
       "24          0\n",
       "25          1\n",
       "26          0\n",
       "27          1\n",
       "28          0\n",
       "29          1\n",
       "..        ...\n",
       "388         1\n",
       "389         0\n",
       "390         1\n",
       "391         0\n",
       "392         1\n",
       "393         1\n",
       "394         1\n",
       "395         0\n",
       "396         1\n",
       "397         0\n",
       "398         1\n",
       "399         1\n",
       "400         0\n",
       "401         1\n",
       "402         0\n",
       "403         1\n",
       "404         0\n",
       "405         1\n",
       "406         1\n",
       "407         0\n",
       "408         0\n",
       "409         0\n",
       "410         0\n",
       "411         0\n",
       "412         0\n",
       "413         1\n",
       "414         0\n",
       "415         1\n",
       "416         1\n",
       "417         0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = pd.read_csv('s3://s3.sagemaker.end2endtitanic.7ededbe5308646a3adbc/batch-inference/test.csv.out',names=['Survived'])\n",
    "output = pd.DataFrame( {'PassengerId': ,'Survived': (tt<=0.5) + 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
